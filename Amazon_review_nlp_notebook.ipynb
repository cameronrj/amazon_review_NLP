{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86350b86",
   "metadata": {},
   "source": [
    "### Define Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db523878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a data class for all the data being loaded\n",
    "\n",
    "class Sentiment:\n",
    "    negative = \"negative\"\n",
    "    neutral = \"neutral\"\n",
    "    positive = \"positive\"\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "#Define sentiment score in review class based of star rating (used to allow NLP ML later)\n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.negative\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.neutral\n",
    "        else:\n",
    "            return Sentiment.positive\n",
    "        \n",
    "        \n",
    "#Create class to even out Positive and negative training data as not to indroduce bias into the ML model\n",
    "class ReviewContainer:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews\n",
    "      \n",
    "    #create method to extract text from each review\n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]\n",
    "        \n",
    "    def evenly_dist(self):\n",
    "        negative = list(filter(lambda x: x.sentiment == Sentiment.negative, self.reviews))\n",
    "        positive = list(filter(lambda x: x.sentiment == Sentiment.positive, self.reviews))\n",
    "        positive_shrunk = positive[:len(negative)]\n",
    "        self.reviews = negative + positive_shrunk\n",
    "        random.shuffle(self.reviews)\n",
    "        print(\"No. of negative: \" + str(len(negative)))\n",
    "        print(\"No. of positive: \" + str(len(positive_shrunk)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b964a08b",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af8a7bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"reviewerID\": \"A1F2H80A1ZNN1N\", \"asin\": \"B00GDM3NQC\", \"reviewerName\": \"Connie Correll\", \"helpful\": [0, 0], \"reviewText\": \"I bought both boxed sets, books 1-5.  Really a great series!  Start book 1 three weeks ago and just finished book 5.  Sloane Monroe is a great character and being able to follow her through both private life and her PI life gets a reader very involved!  Although clues may be right in front of the reader, there are twists and turns that keep one guessing until the last page!  These are books you won't be disappointed with.\", \"overall\": 5.0, \"summary\": \"Can't stop reading!\", \"unixReviewTime\": 1390435200, \"reviewTime\": \"01 23, 2014\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "#Openning file in same directory\n",
    "file_name = './Books_small_10000.json'\n",
    "\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22d69a61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I bought both boxed sets, books 1-5.  Really a great series!  Start book 1 three weeks ago and just finished book 5.  Sloane Monroe is a great character and being able to follow her through both private life and her PI life gets a reader very involved!  Although clues may be right in front of the reader, there are twists and turns that keep one guessing until the last page!  These are books you won't be disappointed with.\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "# Use above print to find dictionary keys to print corresponding values. Current file is not of type dict so need to convert\n",
    "\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        print(review['reviewText'])\n",
    "        print(review['overall'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88e8af16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I hoped for Mia to have some peace in this book, but her story is so real and raw.  Broken World was so touching and emotional because you go from Mia's trauma to her trying to cope.  I love the way the story displays how there is no \"just bouncing back\" from being sexually assaulted.  Mia showed us how those demons come for you every day and how sometimes they best you. I was so in the moment with Broken World and hurt with Mia because she was surrounded by people but so alone and I understood her feelings.  I found myself wishing I could give her some of my courage and strength or even just to be there for her.  Thank you Lizzy for putting a great character's voice on a strong subject and making it so that other peoples story may be heard through Mia's.\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "#Above code works to find individual reviews and rating, use this to create a list of every review and rating. \n",
    "#Use review class to append as a review ibject\n",
    "\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'],review['overall']))\n",
    "\n",
    "#Class allows us to use integer to select review tuple and 'text', 'sentiment' or 'score' to specify the body of the review or its rating\n",
    "print(reviews[5].text)\n",
    "print(reviews[5].sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ca08bd",
   "metadata": {},
   "source": [
    "### Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92b1037f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c877f956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of negative: 513\n",
      "No. of positive: 513\n",
      "No. of negative: 131\n",
      "No. of positive: 131\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "\n",
    "#split review data to use to train and test ML algorithm\n",
    "train, test = train_test_split(reviews, test_size = 0.2, random_state = 42)\n",
    "\n",
    "train_container = ReviewContainer(train)\n",
    "train_container.evenly_dist()\n",
    "\n",
    "test_container = ReviewContainer(test)\n",
    "test_container.evenly_dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3106ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data into text and sentiment (X and y in ML algorithm)\n",
    "X_train = train_container.get_text()\n",
    "y_train = train_container.get_sentiment()\n",
    "\n",
    "# likewise split test data into text and sentiment (X and y)\n",
    "X_test = test_container.get_text()\n",
    "y_test = test_container.get_sentiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e261d2",
   "metadata": {},
   "source": [
    "#### Bag of words vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc197e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x9625 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 75 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "#Use bag of words to create a numerized version of review text e.g. each word is assigned a row and counted in a vector when it appears in a review\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "\n",
    "X_test_vectors = vectorizer.transform(X_test)\n",
    "\n",
    "X_train_vectors[0]\n",
    "X_test_vectors[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb691aff",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcea5249",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3aa5df17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive'], dtype='<U8')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel = 'linear')\n",
    "\n",
    "clf_svm.fit(X_train_vectors, y_train)\n",
    "# Show prediction for first review\n",
    "clf_svm.predict(X_test_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65697009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you can, read the first 4-5 pages, you will immediately if you want to read more or not. As for me, I've rated The Witness two stars because I had trouble relating to the main character (girl, 16, she is a genious - no problem with that - but she can do anything, dancing like shakira, finding out what the FBI needed years of hard work to know by just googling; she is also very beautiful, she has great insight, she is completely good - no grey shade, she'll go straight to heaven)  and clich&eacute;d (girl raised by a strict mother rebels). The story is no too complex either so... Two stars.\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "#actual text & sentiment from first review\n",
    "print(X_test[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b34ef2",
   "metadata": {},
   "source": [
    "#### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb5a775d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype='<U8')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_decision = DecisionTreeClassifier()\n",
    "clf_decision.fit(X_train_vectors, y_train)\n",
    "# Show prediction for first review\n",
    "clf_decision.predict(X_test_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1966902a",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2305fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive'], dtype='<U8')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit(X_train_vectors.toarray(), y_train)\n",
    "# Show prediction for first review\n",
    "clf_gnb.predict(X_test_vectors[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24e950b",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e76dbea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive'], dtype='<U8')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(X_train_vectors, y_train)\n",
    "# Show prediction for first review\n",
    "clf_log.predict(X_test_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42667309",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e847a4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9892787524366472\n",
      "1.0\n",
      "0.9844054580896686\n",
      "0.9668615984405458\n"
     ]
    }
   ],
   "source": [
    "#Pass test data through ML models to see how well they score on mean accuracy\n",
    "\n",
    "print(clf_svm.score(X_train_vectors, y_train))\n",
    "print(clf_decision.score(X_train_vectors, y_train))\n",
    "print(clf_gnb.score(X_train_vectors.toarray(), y_train))\n",
    "print(clf_log.score(X_train_vectors, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "56c57ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82442748 0.82442748]\n",
      "[0.67896679 0.65612648]\n",
      "[0.83333333 0.83076923]\n"
     ]
    }
   ],
   "source": [
    "# Pass test data through ml models and evaluate their f1_scores\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(f1_score(y_test, clf_svm.predict(X_test_vectors), average = None, labels = [Sentiment.positive, Sentiment.negative]))\n",
    "print(f1_score(y_test, clf_decision.predict(X_test_vectors), average = None, labels = [Sentiment.positive, Sentiment.negative]))\n",
    "print(f1_score(y_test, clf_log.predict(X_test_vectors), average = None, labels = [Sentiment.positive, Sentiment.negative]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8c00f6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'negative'], dtype='<U8')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Qualitative test\n",
    "\n",
    "test_set = ['Great book, would recommend', 'I thouroughly enjoyed this purchase', 'The was a poor read']\n",
    "test_set_vect = vectorizer.transform(test_set)\n",
    "\n",
    "clf_log.predict(test_set_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100235b9",
   "metadata": {},
   "source": [
    "#### Use a grid model to tune the ML algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3f375eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.41761489, 0.4894989 , 0.4553153 , 0.52656617, 0.45564137,\n",
       "        0.47928734, 0.43006668, 0.46594052, 0.49164701, 0.52843781]),\n",
       " 'std_fit_time': array([0.03012064, 0.02166058, 0.01635343, 0.04539253, 0.02144911,\n",
       "        0.00689959, 0.00464009, 0.00909492, 0.03748035, 0.05264262]),\n",
       " 'mean_score_time': array([0.10853539, 0.11447353, 0.10506654, 0.13060327, 0.09372711,\n",
       "        0.11356897, 0.09373569, 0.11343985, 0.09875398, 0.13222017]),\n",
       " 'std_score_time': array([1.28396386e-02, 3.64179497e-03, 2.20242901e-02, 1.03787136e-02,\n",
       "        1.39653672e-02, 5.83483432e-03, 1.19276028e-05, 9.17844476e-03,\n",
       "        1.35660096e-02, 1.85099437e-02]),\n",
       " 'param_C': masked_array(data=[1, 1, 2, 2, 3, 3, 4, 4, 8, 8],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
       "                    'linear', 'rbf', 'linear', 'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'kernel': 'rbf'},\n",
       "  {'C': 2, 'kernel': 'linear'},\n",
       "  {'C': 2, 'kernel': 'rbf'},\n",
       "  {'C': 3, 'kernel': 'linear'},\n",
       "  {'C': 3, 'kernel': 'rbf'},\n",
       "  {'C': 4, 'kernel': 'linear'},\n",
       "  {'C': 4, 'kernel': 'rbf'},\n",
       "  {'C': 8, 'kernel': 'linear'},\n",
       "  {'C': 8, 'kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.8592233 , 0.86407767, 0.83980583, 0.8592233 , 0.83980583,\n",
       "        0.85436893, 0.84466019, 0.85436893, 0.84466019, 0.85436893]),\n",
       " 'split1_test_score': array([0.83414634, 0.80487805, 0.82439024, 0.80487805, 0.83902439,\n",
       "        0.80487805, 0.83902439, 0.80487805, 0.83902439, 0.80487805]),\n",
       " 'split2_test_score': array([0.81463415, 0.8       , 0.80487805, 0.8097561 , 0.8       ,\n",
       "        0.8       , 0.8       , 0.8       , 0.8       , 0.8       ]),\n",
       " 'split3_test_score': array([0.85365854, 0.87317073, 0.82926829, 0.86341463, 0.82439024,\n",
       "        0.85853659, 0.82926829, 0.85853659, 0.82926829, 0.85853659]),\n",
       " 'split4_test_score': array([0.86829268, 0.87317073, 0.87804878, 0.88292683, 0.86341463,\n",
       "        0.88292683, 0.86341463, 0.88292683, 0.86341463, 0.88292683]),\n",
       " 'mean_test_score': array([0.845991  , 0.84305944, 0.83527824, 0.84403978, 0.83332702,\n",
       "        0.84014208, 0.8352735 , 0.84014208, 0.8352735 , 0.84014208]),\n",
       " 'std_test_score': array([0.01926031, 0.03336789, 0.02420189, 0.03107133, 0.02083389,\n",
       "        0.03233028, 0.0208537 , 0.03233028, 0.0208537 , 0.03233028]),\n",
       " 'rank_test_score': array([ 1,  3,  7,  2, 10,  4,  8,  4,  8,  4])}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search allows us to test different outputs using different parameters within our prediction models\n",
    "# We can then choose the parameters with the most accurate results\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#parameters = { 'C': (1,2,3,4,8)}\n",
    "parameters = {'C': (1,2,3,4,8), 'kernel': ('linear', 'rbf')}\n",
    "#log = LogisticRegression()\n",
    "svc = svm.SVC()\n",
    "#clf = GridSearchCV(log, parameters, cv=5)\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "clf.fit(X_train_vectors, y_train)\n",
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6698e7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8358778625954199\n"
     ]
    }
   ],
   "source": [
    "#Highest accuracy came from C=1, kernel = 'rbf' SVC alrgorithm\n",
    "\n",
    "clf_new = svm.SVC(kernel = 'rbf', C =1)\n",
    "clf_new.fit(X_train_vectors, y_train)\n",
    "print(clf_new.score(X_test_vectors, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed5eb31",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764054c9",
   "metadata": {},
   "source": [
    "#### Results\n",
    "In this project, I used several supervised ML models to predict whether a product review from a customer is positive or negative. \n",
    "\n",
    "A dataset of 10'000 book reviews was used to train several ML models:\n",
    " - Support Vector Machine\n",
    " - Decision Tree\n",
    " - Naive Bayes\n",
    " - Logistic Regression\n",
    " \n",
    "These models were then refined to obtain the most accurate preditions. The dataset was split 80:20 into training and testing sets. Once the models were trained, inputing reviews and their ratings (1-5 stars, translated into positive, negative and neutral) to train the model, the model was used to make precitions on the remainder of the dataset reviews. These predictions were compared the actual review rating n order to determine the accuracy of the ML models. \n",
    "\n",
    "Additionaly, a grid model was used to refine the ML model, passing through different values for specific parameters within the model. The best combination of these parameters were chosen in order to obtain the most accurate model.\n",
    "\n",
    "The final model chosen was SVM model, using values 'rbf' and '1' for parameter 'kernal' and 'C'. The accuracy of this model was **84%**.\n",
    "\n",
    "Although the model accuracy was relativey high, there is room for improvement.\n",
    "\n",
    "#### Future steps\n",
    "\n",
    "- Improve vectorizer: Currently a tfidf vectorizer is being used. This weighs the key words like \"bad\", \"good\", \"excellent\" and \"terrible\" higher than non-positive or negative descriptive words like \"the\", \"this\", \"I\" etc by giving a smaller weighting to words that appear more often. However, this method does not decipher between the less frequent words to determine if they are influential on the positiveness or negativeness of a reiview. For example, if the word \"paramount\" wasn't used frequently it would be weighted highly, but this does not provide an insight as to whether the review is positive or negative. A better model would be able to map words that do effect the review, for example adjectives, and weight these higher than similarly less frequently used word that don't convey positive or negative opinions.\n",
    "<br>   \n",
    "  \n",
    "- Refine the data used to train the model: The model uses the entire review submitted by a customer, counting every word and every varyation of a word (e.g. good and good!). One way to improve the models accuracy would be to refine these reviews to contain mainly key words. This could be achieved by selectively stripping words that can be confidently disregarded.\n",
    "<br>\n",
    "  \n",
    "- Increase data used to train the model: An obvious way to increase the accuracy of the model would be to increase the number of reviews used to train the model, thus allowing the ML algorithm to create a more accurate and detailed model of positive and negative words.\n",
    "<br>\n",
    "  \n",
    "- The model could also be used to classify the type of product being reviewed: As well as using the review to predict a negative and positive rating, the ML model could be used to classify the product of a review, for example, if the product was clothing, electrical, home etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573722aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
